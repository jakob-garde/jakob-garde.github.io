---
title: "Manually parsing the McStas DSL"
---


# Text parsing is fun

*This article is a project description, but first, a disclaimer and some context. For years I worked on the open-source software package McStas as a core developer at DTU Physics (2015-2020), which is why I know so much about the McStas core software. Currently re-visiting the project on a completely volountary and independent basis. All statements below are thus reflections of my personal findings and opinions, and nothing more.*


Recently while researching and learning more C, I happened upon custom parsing and thought it was pretty cool. Turns out that people have been parsing many things manually since way back when, and done it very well.

Parsing sometimes gets a bad rep afterall, and seems like a thing that "should just work", something we should have tools for.

Plenty og tools were indeed written during the Bell Labs era and given names like Yacc or (later on) bison. These were ancestors of the infamous GNU, one of the most hoofed software animal coming out of the 1980's.

Yet at closer look, parsing is not just about reading JSON files or writing custom compilers, supposedly a common practice in those days. It probably owes its fame to one of the wildest  programming paradigms: META programming.

If I were to explain the importance of meta programming to a non-programmer, I'd point to the widespread usage of scripting languages like Python, JavaScript, Ruby, and Perl. All very popular and with the "reflection" programming-language feature which is notably lacking in C.


# What is META programming?

Meta programming means writing a program that writes another program. This is admittedly a two-step process: First you write and execute a program that outputs the source code for another program, which is compiled and executed separately, and often automatically.

With meta programming we may configure certain things abstractly, let the meta process take its course, and reap the automated benefits. This can be much better than writing everything out in tedious detail, in situations where there could be a lot of repetition, or when multiple lines of code is needed to do simple things.

If this sounds a bit complicated, well, it is: Meta programs can become incomprehensible to anyone but their authors. Some resemble convoluted math proofs that skip way too many steps, but I digress.

Despite the potential for obscurity, meta programming comes with enormous power, and allows us to do many things that are quite clever and time-saving.


# Are we still using that?

Also McStas, a physics simulation package originally dating from 1997, was indeed written by people wielding the power of META. As a physics simulation, performance requirements dictated that it was written in C. Thus the meta program had to output C code.

Why not write the meta program in C, too? This was not as uncommon as it sounds, back then, and to this day, C is very dependable and portable.

So from a certain perspective it was a pretty great choice. However let's circle back to those furry software animals mentioned above, specifically BISON and FLEX.

The BISON/FLEX combo is known as a parser generator. It is not just a parser, nor just a code generator. It is a parser that uses code generation to generate a parser. Spoken plainly, it is a C program that takes a few configuration files and outputs C source code for a parser.


# Overly contrived example

In the BISON/FLEX system you write rules that dictate how input text must be structured to be accepted as a valid meta program - meaning the allowed words, sentences and sequences.

For example, let's insist that an email must contain the following elements:

<pre>
"email: greeting body farewell"
</pre>

Breaking it down further, the "greeting" could be defined as

<pre>
"greeting: formality name"
"body: TEXT"
"farewell: formality name"
</pre>

With this, we must go on to define what qualifies as a "formality" and a "name". A name must be capitalized, a formality belongs to a group of specific phrases, and so on and so forth. If we keep up this definition process, we will at some point have described an email well enough for our purposes.

This is what's called a "domain specific language" or DSL for short.

Notice how the rules above are written in an abstract and beautiful way that resembles mathematics. Amazing, isn't it?


# Experimental physics cross-over

Imagine an experimental physicist with sporadic access to highly expensive and complex equipment. This "instrument" must be configured exactly right for the experiment to be a success - but we don't have access to it beforehand.

In order to solve this connundrum, we resort to simulation. We simulate the experiment in software, allowing us to tweak the setup and plan the (virtual) experiment. The simulation could even show you how to configure the equipment optimally, which is great, then we don't have to spend (as much) time tuning the instrument on-site.

Since simulation code is fickle and complicated, we use-existing software components which match the physical instrument as closely as possible. We don't want to write the whole simulation program from scratch - although people in the real reality actually did for years - until better options was developed. One of these "better options" is called McStas.

In other words, people created easier ways to configure their simulation in terms of pre-written software components. To keep it all neat and tight, they used BISON/FLEX to create the parser that would make all this happen.

This parser would convert two types of configuration files - components and instruments - into finished simulation programs. This tool is then called mcstas (and mcxtrace), and the  rules that govern how these configuration files must be written, is called the McStas DSL.


# McStas is not optimized for (my kind of) change

This software strategy was a great success, and still is. But like most software it has its issues and limitations and a few vectors of potential improvement.

Presented below are three major issues with the system as-is.

The FLEX/BISON setup is rather convoluted. In order to use it, you need to keep track of grammar-rules (.y) and lexer (.l) files. The flex/bison command-line tools take these configuration files as their input, and outputs the C code which comprise the actual DSL parser.

This takes a few steps, so when *debugging* we have to go through the entire build process:

- 1) edit the flex/bison configuration files
- 2) execute flex/bison cli tools
- 3) include the generated parser code into the 'mcstas' tool and compile
- 4) run the generated mcstas parser-tool on a sample instrument file
- 5) the mcstas parser how outputs source code for the simulation
- 6) compile the simulation source
- 7) run the executable and check this simulation's output files (using other tools)

The process is automated, but we might be hard pressed to use this level of automation and still retain a convenient/efficient development setup.

### Problem a) The lack of a convenient development loop

The build process is lengthy and inconvenient for tight development loops, and quite hard to debug.

We can't debug the parser itself since flex/bison files can't be debugged and the resulting parser code is incomprehensible and not to be trifled with.

The generated simulation code is monolithic and hard to read and navigate.

### Problem b) Error messages are very generic

Another consequence of using flex/bison is that the error codes are quite generic.

This means that when users work with their instruments they may have a hard time figuring out what that error message even means. The line numbers are generated, but beyond a few special cases, there isn't any more information to go by.

It isn't terrible, but still leaves a lot to be desired in terms of usability.

### Problem c) Inaccessible simulation core algorithms

The biggest problem with the current mcstas setup from a developer's perspective, is the inaccessibility of the core algorithms. For years, mcstas has run the same simulation original ray tracing loop.

At some point, MPI was introduced, and it has also been ported to GPUs with a tool called OpenACC. To make the OpenACC port possible, we had to heavily edit the code generator at the time, again using the long-winded process sketched above. These changes brought performance improvements, but no now capabilities, and came at a significant complexity cost.

My opinion here is that when experimenting with core algorithms is inconvenient, it happens less often.


# Can legacy code be fixed or salvaged?

Writing a new McStas DSL parser and code generator seemed unfeasible or not worth the time.

People built tools on top of the core instead, developed onion rings of software stack - as you do. Mostly, the basic simulation tools seem to rest quietly below. Notable exceptions is the Union components and advanced event logging. (However, my awareness is not completely up to date here).

The problem isn't that the people aren't willing or able to innovate - but that it was become harder to do so as time goes by, onion layers build up, and knowledge is invested elsewhere.

At some point I needed a programming challenge and started writing a parser for the McStas DSL from scratch in C, this was during the 2020 pandemic. Writing it was a delightful experience and a few months ago I took on the task of modernizing that code.

Currently I wanted a nice prototype, and hopefully present an alternative strategy and viable method. A working version of this parser is available here: [mcparse].

### Testing the custom parser

Parser output on the bulk data: [mcparse/example_output_0.1.0.md](https://github.com/climbcat/mcparse/blob/main/example_output_0.1.0.md)

Examples messages compared with mcstas: [mcparse/failtest_output_0.1.0.md](https://github.com/climbcat/mcparse/blob/main/failtest_output_0.1.0.md)


# What custom code brings to the table

Yet another project called [mctrace] was developed in these past months. Its purpose is to show the runtime viability of the [mcparse] generated code as it combines with other custom algorithms, and the ported/re-packaged McStas core (static) simulation library, now named [simcore.h](https://github.com/climbcat/mctrace/blob/main/simcore/simcore.h) and [simlib.h](https://github.com/climbcat/mctrace/blob/main/simcore/simlib.h).

The [mctrace] project currently produces run-time simulation output and mcdisplay- and mcplot-like visuals. The main point was to develop, test and validate the code generated by mcparse.

The present code-base is a re-imagining of the mcstas core. The physics are exactly the same, yet now with many more potential capabilities. It enables developers with C knowledge to write their own, custom ray-tracing procedures for McStas. Every (ported) component and instrument is available as a C++ source file.

It is in an early version with limited components and a single tested instrument, but still - the hard problems and road-blocks have all been solved. The programming pathways are avalable for developers to dynamically configure and combine components as you please, apply algorithms, frameworks, methods, runtime data analysis', custom visuals and data formats, all with full C++ compliance.

Adding such advanced capabilities to a complex system becomes possible when the code is readily available, modular, quick and easy to debug, and runs without any required frameworks or build systems.

So, what's the catch? The production/release version is a ways off and likely never to be realized, since noone is paying me to do this. It was a lot of fun though, learned a whole lot, and I hereby consider the McStas DSL wheel re-invented!

[mcparse]: https://github.com/climbcat/mcparse
[mctrace]: https://github.com/climbcat/mctrace





