---
title: "Manually parsing the McStas DSL"
---


# Text parsing is fun

*This article is a project description, but first, a disclaimer and some context. For years I worked on the open-source software package McStas as a core developer at DTU Physics (2015-2020), which is why I know so much about the McStas core software. Currently re-visiting the project on a completely volountary and independent basis. All statements below are thus reflections of my personal findings and opinions, and nothing more.*


Recently while researching and learning more C, I happened upon custom parsing and thought it was pretty cool. Turns out that people have been parsing many things manually since way back when, and done it very well.

Parsing sometimes gets a bad rep afterall, and seems like a thing that "should just work", something we should have tools for.

Plenty og tools were indeed written during the Bell Labs era and given names like Yacc or (later on) BISON. These were ancestors of the infamous GNU, one of the most hoofed software animal coming out of the 1980's.

Yet at closer look, parsing is not just about reading JSON files or writing custom compilers (a common practice in those days). It is the first component of one of the most powerful programming paradigms: META programming.


# What is META programming?

Meta programming means writing a program that writes another program. This is admittedly a two-step process: First you write and execute a program that outputs the source code for another program, which is compiled and executed separately, and often automatically.

With meta programming we may configure certain things abstractly, let the meta process take its course, and reap the automated benefits. This can be much better than writing everything out in tedious detail, in situations where there could be a lot of repetition, or when multiple lines of code is needed to do simple things.

If this sounds a bit complicated, well, it is: Meta programs can become incomprehensible to anyone but their authors. Some resemble convoluted math proofs that skip way too many steps, but I digress.

Despite the potential for obscurity, meta programming comes with enormous power, and allows us to do many things that are quite clever and time-saving.

Were I to explain the importance of meta programming to a non-programmer, I'd point to the widespread usage of scripting languages like Python, JavaScript, Ruby, and Perl. All very popular - and, amongst other things, have the "reflection" programming-language feature which is notably lacking in C. 

Therefore, C programmers who wanted to do meta programming had to manually parse configuration files and generate their own code. Sure it took a little longer than writing a Python script, but it was a straight-forward method that worked just fine.


# Are we still using that?

Also McStas, a physics simulation package originally dating from 1997, was indeed written by people wielding the power of META. As a physics simulation, performance requirements dictated that it was written in C. Thus the meta program had to output C code.

Why not write the meta program in C, too? This was a dependable and portable, and from a certain perspective, a pretty great choice. However first, we should spend a little more with those software animals mentioned above, specifically BISON and FLEX.

The BISON/FLEX combo is known as a parser generator. It is not just a parser, not just a code generator, but both, and makes meta programming in C easier. A tool that reads in configuration files and outputs C source-code for a program that parses text according to specifications in those configuration files.


# Overly contrived example

In the BISON/FLEX system you write rules that dictate how the meta program / an input text file should be structured. You specify "grammar rules" for the allowed words, sentences and sequences of the DSL.

For example, if we wanted to parse emails, we could say that it should contain the following sections:

<pre>
"email: greeting body farewell"
</pre>

Breaking it down further, the individual elements should be defined as well:

<pre>
"greeting: formality name"
"body: TEXT"
"farewell: formality name"
</pre>

And even further:

<pre>
"formality: 'Hello' or 'Dear'"
"body: TEXT"
"farewell: 'Regards' or TEXT"
"name: FLCAP_TEXT
</pre>

A name must be first-letter capitalized, a formality belongs to a group of specific phrases, and so on and so forth. If we keep up this definition process for long enough, we will at some point have described an email well enough for our purposes. Then we could start parsing emails and do something with it.

The resulting rules for writing this sort of email is called a "domain specific language" or DSL for short.

Notice how the rules above are written in an abstract and beautiful way that resembles mathematics? This makes the system simpler to deal with; we no longer need to write an involved parser program, but can instead just write concise rules in a config file.


# Experimental physics cross-over

With all this in mind, let's have a look at a real life meta-programming example.

Imagine an experimental physicist with sporadic access to highly expensive and complex equipment. This "instrument" must be configured exactly right for the experiment to be a success - but we don't have access to it beforehand.

In order to solve this connundrum, experimental physicists will often resort to simulation. We simulate the experiment in software, allowing us to tweak the setup and plan the experiment. The simulation could even show you how to configure the equipment optimally, which is great, then we don't have to spend as much time tuning the instrument on-site.

Initially, people wrote the whole simulation program from scratch - until standardized and reliable options were developed.

One of these options is McStas.

To keep it all neat and tight, it uses BISON/FLEX to define a text parser. This parser would convert two types of configuration files - components and instruments - into finished simulation programs. The rules that governe these config files is what is meant by "the McStas DSL".


# McStas is not optimized for (my kind of) change

This software strategy was a great success, and still is. But like most software it has its issues and limitations and a few vectors of potential improvement.

Presented below are three major issues with the system as-is.

The FLEX/BISON setup is rather convoluted. In order to use it, you need to keep track of grammar-rules (.y) and lexer (.l) files. The flex/bison command-line tools take these configuration files as their input, and outputs the C code which comprise the actual DSL parser.

This takes a few steps, so when *debugging* we have to go through the entire build process:

- 1) edit the flex/bison configuration files
- 2) execute flex/bison cli tools
- 3) include the generated parser code into the 'mcstas' tool and compile
- 4) run the generated mcstas parser-tool on a sample instrument file
- 5) the mcstas parser how outputs source code for the simulation
- 6) compile the simulation source
- 7) run the executable and check this simulation's output files (using other tools)

The process is automated, but we might be hard pressed to use this level of automation and still retain a convenient/efficient development setup.

### Problem a) The lack of a convenient development loop

The build process is lengthy and inconvenient for tight development loops, and quite hard to debug.

We can't debug the parser itself since flex/bison files can't be debugged and the resulting parser code is incomprehensible and not to be trifled with.

The generated simulation code is monolithic and hard to read and navigate.

### Problem b) Error messages are very generic

Another consequence of using flex/bison is that the error codes are quite generic.

This means that when users work with their instruments they may have a hard time figuring out what that error message even means. The line numbers are generated, but beyond a few special cases, there isn't any more information to go by.

It isn't terrible, but still leaves a lot to be desired in terms of usability.

### Problem c) Inaccessible simulation core algorithms

The biggest problem with the current mcstas setup from a developer's perspective, is the inaccessibility of the core algorithms. For years, mcstas has run the same simulation original ray tracing loop.

At some point, MPI was introduced, and it has also been ported to GPUs with a tool called OpenACC. To make the OpenACC port possible, we had to heavily edit the code generator at the time, again using the long-winded process sketched above. These changes brought performance improvements, but no now capabilities, and came at a significant complexity cost.

My opinion here is that when experimenting with core algorithms is inconvenient, it happens less often.


# Can legacy code be salvaged?

Writing a new McStas DSL parser and code generator seemed unfeasible or not worth it.

Instead, people built tools on top of the core and developed onion rings of software stack - as you do. The basic simulation code that did all of the actual simulation work, seemed to rest quietly below, neatly wrapped away, steeped in CMake and Python. Notable innovative exceptions is the Union components and advanced event logging.

My critique isn't that the people aren't willing or able to innovate - but that it becomes harder to do so as time and stack layers build up, and knowledge is invested elsewhere. Which is arguably a shame. We know how innovative ingenious people can be when the proper tools are available.

At some point I needed a programming challenge, and started writing a parser for the McStas DSL from scratch in C. This was during the 2020 pandemic. Writing it was a delightful experience, so a few months ago I took on the task of modernizing that code. Aiming at a serious prototype and to present a viable, alternative take on the mcstas core layer.

### Testing the custom parser

A working version of my custom parser is available here: [mcparse]

Parser output on the bulk data: [mcparse/example_output_0.1.0.md](https://github.com/climbcat/mcparse/blob/main/example_output_0.1.0.md)

Examples messages compared with mcstas: [mcparse/failtest_output_0.1.0.md](https://github.com/climbcat/mcparse/blob/main/failtest_output_0.1.0.md)


# What custom code brings to the table

Reading the generated mcstas simulation code it becomes clear that it is monolithic and not nearly as modular as it could be. For example, it generates types and initialization code, instead of extracting this into helper libraries. All library code is in-lined and there are duplicate sections targetting various hardware platforms.

Another issue is the way that geometry is handled internally. Today, pepole always use 4x4 affine transformation matrices for their 3D code, but the mcstas implementation used 3x3 rotaion matrices and a separate transformation vector. This is just harder to scrutinize and work with. 

Since the parser was already halfway done, I decided to build a code generator into it. It outputs very modular code: One .h file for each component plus one meta file in total, and one .h file for each instrument. The rest is library code. These generated files can be included ad-lib into any project along with now-salvaged runtime simulation libraries.

The salvaged McStas static core runtime simulation code is found here: [simcore.h](https://github.com/climbcat/mctrace/blob/main/simcore/simcore.h) and [simlib.h](https://github.com/climbcat/mctrace/blob/main/simcore/simlib.h).

Another project called [mctrace] was developed to demonstrate runtime viability of the code generated by this alternative strategy. It combines custom algorithms with code-generated component- and instrument code. It produces real-time simulation output and mcdisplay- and mcplot-like visuals within a simple wireframe-based 3D user interface.

The main point was to develop, test and validate the code generated by mcparse. It also features modernized component initialization using 4x4 affine transformations, custom visualization hooks for mcdisplay/mcplot, and exemplifies how to write custom trace algorithms.


# Liberate verified physics code

Years and decades has gone into writing, testing and verifying the mcstas components, which make them quite valuable. Unfortunately these gems were not readily available to use in different contexts.

Using the present results, developers with C knowledge can write their own, custom ray-tracing procedures for McStas. Every ported component and instrument is available as a C++ source file, and porting more components is straight-forward.

The mcparse/mctrace project is imited as any early version, but still - most hard problems and road-blocks have been solved: Demonstrated pathways to configure and combine as you please, apply algorithms, frameworks, methods, runtime data analysis', custom visuals and data formats, all with full C++ compliance.

Adding advanced capabilities to a complex system becomes possible when the code is readily available, modular, quick and easy to run and debug, and does so without any required frameworks or build systems.

The physics is the same, yet now with many more possible capabilities.

So, what's the catch? The production/release version is still on the horizon. Realizing it would require a degree of funding and community support. So far the project has been a lot of fun and very satisfying, I learned a whole lot, and hereby consider the McStas DSL wheel re-invented!

[mcparse]: https://github.com/climbcat/mcparse
[mctrace]: https://github.com/climbcat/mctrace





